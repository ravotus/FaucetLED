FreeRTOS Thread-Aware debugging
===============================
1. Add the following to Project properties->MCU GCC Linker->Miscellaneous->Linker flags
    -Wl,--undefined=uxTopUsedPriority

2. Add the following somewhere in your source:
    #ifdef __GNUC__
    #define USED __attribute__((used))
    #else
    #define USED
    #endif
    const uint32_t USED uxTopUsedPriority = configMAX_PRIORITIES - 1;

3. Edit your debug configuration .cfg file (not sure if ProjectName.cfg or .custom.cfg is correct) and add:
    $_TARGETNAME configure -rtos auto
   (Right after the include of stm32l4.cfg)

4. Open the debug configuration, go to the Startup tab, and uncheck the "Set Breakpoint At: <main>" box, or set the breakpoint
to a time after the tasks have been added, such as vTaskStartScheduler(). Otherwise, the debugger will fail to start due to
not knowing about the FreeRTOS tasks and give a cryptic error saying "Invalid selected thread."

Note: If you still have issues even after using the correct for .cfg corresponding to your launch configuration,
ensure that the temporary "main" breakpoint is removed. Sometimes it hangs around after a "normal" debugging session.

For more info, see:
http://www.openstm32.org/forumthread2824

USART DMA
=========
For the HAL layer to clear the Tx state properly, the USART global interrupt must be enabled as well as both the 
Tx and Rx interrupts. Furthermore, it appears that setting/clearing the MINC bit does not seem to take affect - perhaps 
a re-initialization of the peripheral is needed?

ADC Data
========
Need to ensure proper sampling time. Currently, using relatively slow sample rate:
Fadc = 80MHz / 256 = 312.5kHz. tsample_opamp = 1/312.5kHz * (12.5cycle + 47.5cycle) = 192uS => Fsample = 5.208kHz

To convert to float, the following operations need to happen:
1. Shift data left by 3 (multiply by 8) because arm_q15_to_float divides by 32768 to convert away from Q15.
2. Use arm_q15_to_float to conver the data to floating-point.
3. Multiply the resulting data (which will be in the range [0, 1] by the vdda_value to obtain the final value with arm_scale_f32).
The first step can be omitted if the data is left-aligned with a sign bit. I accomplished this by setting the data left-aligned
with an offset of 0, which per the RM means there will be 1 sign bit followed by 12 data bits, exactly the format from step 1.

LED Color Calculations
======================
Hot:
(26, 1) -> (60, 255)
m = (255-1)/(60-26) = 7.470588235294118
b = 1 - m * 26 = -193.23529411764707

Cold:
(21, 1) -> (0, 255)
m = (255-1)/(0-21) = -12.095238095238095
b = 1 - m * 21 = 255.0

Independent Window Watchdog (IWDG)
==================================
Design for a 3s watchdog task, with timeout around 4s, window minimum of 2.5s:
Let LSI_div = 32, LSI_min = 29kHz, LSI_max = 34kHz.
Timeout = 4 * (34000/32) = 4250, but max of 4095 = 3.85s
Window = 2.5 * (29000/32) = 2266
=> Watchdog task < 3.85s, > (4095-2266)/(34000/32) = 1.72s

Export sizes of all symbols
===========================
source tools/env.sh
arm-atollic-eabi-nm.exe --size-sort --radix=d --reverse-sort --special-syms Release/FaucetLED.elf > Release/sizes.txt

Floating-point math
===================
arm_math.h's arm_sqrt_f32() implementation was calling some double-precision code. Either use -fno-math-errno, or change to use
inline assembler with vsqrt.f32 instruction (I chose the latter). powf and logf also appear to use some double-precision calls,
as evidenced by some calls to __adddf3, __aeabi_dsub, and __subdf3 in the sizes output.

Low-Power Modes
===============
12/24/16: Low-power idle is working for the most part with HCLK=100kHz using the SysTick timer. Decided to treat each tick as 1s in low power mode,
giving a granularity of 100000 / 8 = 12500 cycles/tick, better than the full power mode of 10000 cycles (when using HCLK/8 setting).
However, sometimes get a hard fault shortly after startup. I've noticed if I comment out HAL_InitTick() inside of the PostSleepProcessing,
the issue doesn't seem to be reproducible. Investigating the hard fault exception suggests that the issue may lie with the SysTick interrupt
firing inside of HAL_RCC_ClockConfig(). Generally the issue shows up on line 929:
    if(RCC_ClkInitStruct->SYSCLKSource == RCC_SYSCLKSOURCE_HSE)

12/25/16: Figured it out. Need to set the voltage scaling mode back to 1 (high performance) when exiting sleep. The processor
was generating a bus fault when writing the register to actually set the sysclk source back to PLL. This got me thinking about
what actually happens when the clock frequency changes and all the prerequisites that must be in place to do so.

12/26/16: The HAL_InitTick() call seems to pretty badly mess up low-power mode. The TIM7 interrupt appears to pend soon after
the tick is enabled. The only way I found around it was to disable the TIM7 interrupt directly with the NVIC.
I'm not looking at integrating the app in with tickless support. It seems tickless suffers from pretty bad tick drift - 
a 90ms timeout somehow turns into 65ms of real time. Furthermore, the ADC clock divider will need to be changed if the
system clock frequency is changed, otherwise the /256 divider for the original 80MHz clock is obviously a bad idea.

12/27/2016: Should look into running the FreeRTOS demo as a test to sanity check the port after making LP changes.
Also want to look at running the core at a lower frequency. If we can get away with <=48MHz, then can use the MSI directly
instead of having to start the PLL which uses substantial current. Furthermore, could also decrease the AHB clock and/or
the APB clocks to further decrease power consumption.
IMPORTANT: The peripheral clock gates need to be enabled to allow them to be enabled during sleep. See DMA1SMEN and ADCSMEN.

1/15/2017: Decided the easiest way to work around the ADC clock frequency changing issue during LPsleep was just to only enter
Sleep mode when the ADC is running. This ends up being about 20ms of the 100ms main period. Also, running the CPU directly from
the MSI at 48MHz avoids having to start the PLL which substantially saves power. Now the cpu draws 350uA on average while
running the app in a 100ms task. 

1/16/2017: Started measuring whole-board current. Had to remove R14 from the Nucleo board because it was causing the ST-Link to
try to turn on and draw more current. Currents were as follows before removing R14:
'Iuc': 0.00017782794100389227
'Itherm': 0.000159
'Itot': 0.0012302687708123812
'Iopamp': 0.0003182579314564716
'Inucleo': 0.0006918309709189362
'Iref': 1.6499999999999999e-06
'Inucleo_extra': 0.0005140030299150439
'Iamp_shdn': 0.0009120108393559096

1/21/2017: Run TIM2 at /1 clk with period of 255 because timer clock = 400kHz/16*2 = 50kHz. Then,
PWM frequency = 50kHz / 255 = 196Hz. In full-power mode, PWM freq = (48MHz / 16) / 255 = 11.76kHz.

Successfully added support for Stop2 mode (~35uA for Iuc). However, the TIM2 gpio when configured cause the current drawn
to be much higher. Disabling TIM2 doesn't seem to help unless it's completely DeInit'd. 

1/22/2017: Worked around the TIM2 issue by just setting the GPIO back to analog when disabled. Seems to work fine.
Iuc: 3.467368504525317e-05
Decreased opamp to 64 samples for fairly dramantic power savings.
Iuc: 1.2022644346174132e-05
Itot: 0.00010471285480508996

1/31/2017: Should be able to place QFN32 footprint for L4 inside of LQFP32 footprint for L0. They are pin-compatible.
Probably don't need to be reading the reference voltage every time if we can assume Vdda will always be ~3.3V. 

2/2/2017: Playing more with keeping certain opamps on. Seems the external draws the most (or is still driving/being driven).
Ishdn total = 29.5e-6
Ishdn ext opamp always on, int switched = 432e-6
Ishdn int opamp always on, ext switched = 29.5e-6
Ishdn neither: 437e-6
Not temperature dependent

Need to investigate why it seems the current oscillates rapidly when I enabled SHDN (but had never looked at it before).
Possibly the external opamp oscillating due to the piezo input?

3/11/2017: Make sure to set BOR level option byte to level 4 or 5 to ensure proper operation when battery gets low.