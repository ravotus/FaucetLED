FreeRTOS Thread-Aware debugging
===============================
1. Add the following to Project properties->MCU GCC Linker->Miscellaneous->Linker flags
    -Wl,--undefined=uxTopUsedPriority

2. Add the following somewhere in your source:
    #ifdef __GNUC__
    #define USED __attribute__((used))
    #else
    #define USED
    #endif
    const uint32_t USED uxTopUsedPriority = configMAX_PRIORITIES - 1;

3. Edit your debug configuration .cfg file (not sure if ProjectName.cfg or .custom.cfg is correct) and add:
    $_TARGETNAME configure -rtos auto
   (Right after the include of stm32l4.cfg)

4. Open the debug configuration, go to the Startup tab, and uncheck the "Set Breakpoint At: <main>" box, or set the breakpoint
to a time after the tasks have been added, such as vTaskStartScheduler(). Otherwise, the debugger will fail to start due to
not knowing about the FreeRTOS tasks and give a cryptic error saying "Invalid selected thread."

Note: If you still have issues even after using the correct for .cfg corresponding to your launch configuration,
ensure that the temporary "main" breakpoint is removed. Sometimes it hangs around after a "normal" debugging session.

For more info, see:
http://www.openstm32.org/forumthread2824

USART DMA
=========
For the HAL layer to clear the Tx state properly, the USART global interrupt must be enabled as well as both the 
Tx and Rx interrupts. Furthermore, it appears that setting/clearing the MINC bit does not seem to take affect - perhaps 
a re-initialization of the peripheral is needed?

ADC Data
========
Need to ensure proper sampling time. Currently, using relatively slow sample rate:
Fadc = 80MHz / 256 = 312.5kHz. tsample_opamp = 1/312.5kHz * (12.5cycle + 47.5cycle) = 192uS => Fsample = 5.208kHz

To convert to float, the following operations need to happen:
1. Shift data left by 3 (multiply by 8) because arm_q15_to_float divides by 32768 to convert away from Q15.
2. Use arm_q15_to_float to conver the data to floating-point.
3. Multiply the resulting data (which will be in the range [0, 1] by the vdda_value to obtain the final value with arm_scale_f32).
The first step can be omitted if the data is left-aligned with a sign bit. I accomplished this by setting the data left-aligned
with an offset of 0, which per the RM means there will be 1 sign bit followed by 12 data bits, exactly the format from step 1.

LED Color Calculations
======================
Hot:
(26, 1) -> (60, 255)
m = (255-1)/(60-26) = 7.470588235294118
b = 1 - m * 26 = -193.23529411764707

Cold:
(21, 1) -> (0, 255)
m = (255-1)/(0-21) = -12.095238095238095
b = 1 - m * 21 = 255.0

Low-Power Modes
===============
12/24/16: Low-power idle is working for the most part with HCLK=100kHz using the SysTick timer. Decided to treat each tick as 1s in low power mode,
giving a granularity of 100000 / 8 = 12500 cycles/tick, better than the full power mode of 10000 cycles (when using HCLK/8 setting).
However, sometimes get a hard fault shortly after startup. I've noticed if I comment out HAL_InitTick() inside of the PostSleepProcessing,
the issue doesn't seem to be reproducible. Investigating the hard fault exception suggests that the issue may lie with the SysTick interrupt
firing inside of HAL_RCC_ClockConfig(). Generally the issue shows up on line 929:
    if(RCC_ClkInitStruct->SYSCLKSource == RCC_SYSCLKSOURCE_HSE)

12/25/16: Figured it out. Need to set the voltage scaling mode back to 1 (high performance) when exiting sleep. The processor
was generating a bus fault when writing the register to actually set the sysclk source back to PLL. This got me thinking about
what actually happens when the clock frequency changes and all the prerequisites that must be in place to do so.

12/26/16: The HAL_InitTick() call seems to pretty badly mess up low-power mode. The TIM7 interrupt appears to pend soon after
the tick is enabled. The only way I found around it was to disable the TIM7 interrupt directly with the NVIC.
I'm not looking at integrating the app in with tickless support. It seems tickless suffers from pretty bad tick drift - 
a 90ms timeout somehow turns into 65ms of real time. Furthermore, the ADC clock divider will need to be changed if the
system clock frequency is changed, otherwise the /256 divider for the original 80MHz clock is obviously a bad idea.

12/27/2016: Should look into running the FreeRTOS demo as a test to sanity check the port after making LP changes.
Also want to look at running the core at a lower frequency. If we can get away with <=48MHz, then can use the MSI directly
instead of having to start the PLL which uses substantial current. Furthermore, could also decrease the AHB clock and/or
the APB clocks to further decrease power consumption.
IMPORTANT: The peripheral clock gates need to be enabled to allow them to be enabled during sleep. See DMA1SMEN and ADCSMEN.